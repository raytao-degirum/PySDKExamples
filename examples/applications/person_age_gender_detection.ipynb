{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "438aa03a",
   "metadata": {},
   "source": [
    "![Degirum banner](https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/images/degirum_banner.png)\n",
    "## Person detection with additional analytics \n",
    "\n",
    "This notebook is an example how to use DeGirum PySDK to do person head detection with additional analytics.\n",
    "The output of the person head detector is analyzed by the object tracker analyzer to associate the same person over \n",
    "the sequence of frames. Then it is analyzed by the zone analyzer to detect objects within the dedicated zone.\n",
    "Then only objects within that zone are accepted for further processing. For each such object the image around\n",
    "that object is cropped with some crop extent and supplied to the input of two models: age detector and gender classifier.\n",
    "The results of those models are combined to obtain summary result, containing original bbox of the person's head,\n",
    "it's unique track ID, cropped image of the person's head, person's age and gender.\n",
    "\n",
    "The results are aggregated based on the person's track ID. The age/gender results are averaged over all frames on which \n",
    "that person's track ID appears to improve the accuracy of classification. Then the aggregated results are printed.\n",
    "\n",
    "This example uses `degirum_tools.streams` streaming toolkit.\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. Run inference on DeGirum Cloud Platform;\n",
    "2. Run inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN;\n",
    "3. Run inference on DeGirum ORCA accelerator directly installed on your computer.\n",
    "\n",
    "To try different options, you need to specify the appropriate `hw_location` option. \n",
    "\n",
    "When running this notebook locally, you need to specify your cloud API access token in the [env.ini](../../env.ini) file, located in the same directory as this notebook.\n",
    "\n",
    "When running this notebook in Google Colab, the cloud API access token should be stored in a user secret named `DEGIRUM_CLOUD_TOKEN`.\n",
    "\n",
    "The script can use either a web camera or local camera connected to the machine or a video file. The camera index or URL or video file path needs to be specified in the code below by assigning `video_source`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88e17ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure degirum-tools package is installed\n",
    "!pip show degirum-tools || pip install degirum-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac1ad6f-2290-44fe-bcfd-4715f594ce57",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Specify where do you want to run your inferences, model_zoo_url, model names for inference, and video source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d33374c-e516-4b5f-b306-d18bf6392c52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hw_location: where you want to run inference\n",
    "#     \"@cloud\" to use DeGirum cloud\n",
    "#     \"@local\" to run on local machine\n",
    "#     IP address for AI server inference\n",
    "# model_zoo_url: url/path for model zoo\n",
    "#     cloud_zoo_url: valid for @cloud, @local, and ai server inference options\n",
    "#     '': ai server serving models from local folder\n",
    "#     path to json file: single model zoo in case of @local inference\n",
    "# people_det_model_name: name of the model for detecting people heads\n",
    "# age_det_model_name: name of the model for age detection\n",
    "# gender_det_model_name: name of the model for gender classification\n",
    "# video_source: video source for inference\n",
    "#     camera index for local camera\n",
    "#     URL of RTSP stream\n",
    "#     URL of YouTube Video\n",
    "#     path to video file (mp4 etc)\n",
    "hw_location = \"@cloud\"\n",
    "model_zoo_url = \"degirum/public\"\n",
    "people_det_model_name = \"yolov8s_relu6_human_head--640x640_quant_n2x_orca1_1\"\n",
    "age_det_model_name = \"yolov8n_relu6_age--256x256_quant_n2x_orca1_3\"\n",
    "gender_det_model_name = \"mobilenetv2_050_gender--160x160_quant_n2x_orca1_1\"\n",
    "video_source = \"https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/images/WalkingPeople2.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e036ab35-cc8f-4e67-bf5b-f01c470db2a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65d4cd90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Load models\n",
    "#\n",
    "\n",
    "import degirum as dg, degirum_tools\n",
    "import time\n",
    "from degirum_tools import streams as dgstreams\n",
    "\n",
    "# connect to AI inference engine\n",
    "zoo = dg.connect(hw_location, model_zoo_url, degirum_tools.get_token())\n",
    "\n",
    "# load person detection model\n",
    "person_det_model = zoo.load_model(\n",
    "    people_det_model_name,\n",
    "    output_confidence_threshold=0.7,\n",
    "    overlay_show_probabilities=True,\n",
    "    overlay_line_width=1,\n",
    ")\n",
    "\n",
    "# load age detection model\n",
    "age_det_model = zoo.load_model(\n",
    "    age_det_model_name,\n",
    "    overlay_color=(255, 0, 0),\n",
    "    overlay_show_probabilities=True,\n",
    ")\n",
    "\n",
    "# load gender detection model\n",
    "gender_det_model = zoo.load_model(\n",
    "    gender_det_model_name,\n",
    "    output_top_k=1,\n",
    "    overlay_color=(255, 255, 255),\n",
    "    overlay_show_probabilities=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf099d64-6388-4aa7-aee5-767615d8996a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Create analyzers\n",
    "#\n",
    "\n",
    "# create object tracker\n",
    "tracker = degirum_tools.ObjectTracker(\n",
    "    class_list=[person_det_model.label_dictionary[0]],\n",
    "    track_thresh=0.35,\n",
    "    track_buffer=100,\n",
    "    match_thresh=0.9999,\n",
    "    trail_depth=20,\n",
    "    anchor_point=degirum_tools.AnchorPoint.CENTER,\n",
    ")\n",
    "\n",
    "# create zone counter\n",
    "counting_zone = [[[300, 10], [500, 10], [500, 710], [300, 710]]]\n",
    "zone_counter = degirum_tools.ZoneCounter(\n",
    "    counting_zone,\n",
    "    triggering_position=degirum_tools.AnchorPoint.CENTER,\n",
    "    annotation_color=(255, 0, 0),\n",
    ")\n",
    "\n",
    "# create event detector\n",
    "event_name = \"crossing\"\n",
    "event_description = f\"\"\"\n",
    "    Trigger: {event_name}\n",
    "    when: ZoneCount\n",
    "    is greater than: 0\n",
    "    during: [1, frame]\n",
    "    \"\"\"\n",
    "event_detector = degirum_tools.EventDetector(event_description)\n",
    "\n",
    "\n",
    "#\n",
    "# Define cropping gizmo, which accepts only objects in counting zone\n",
    "#\n",
    "class InZoneCroppingGizmo(dgstreams.AiObjectDetectionCroppingGizmo):\n",
    "    def validate_bbox(\n",
    "        self, result: dg.postprocessor.InferenceResults, idx: int\n",
    "    ) -> bool:\n",
    "        \"\"\"Validate detected object.\n",
    "\n",
    "        - result: inference result\n",
    "        - idx: index of object within `result.results[]` list to validate\n",
    "\n",
    "        Returns True if object is accepted to be used for crop, False otherwise\n",
    "        \"\"\"\n",
    "        return any(result.results[idx].get(\"in_zone\", []))\n",
    "\n",
    "\n",
    "#\n",
    "# Create gizmos\n",
    "#\n",
    "source = dgstreams.VideoSourceGizmo(video_source)  # video source\n",
    "person = dgstreams.AiSimpleGizmo(person_det_model)  # person detector\n",
    "analyzer = dgstreams.AiAnalyzerGizmo(\n",
    "    [tracker, zone_counter, event_detector], filters={event_name}\n",
    ")  # analyzer chain with object tracker, zone counter, and event detector with filter by event\n",
    "crop = InZoneCroppingGizmo(\n",
    "    [person_det_model.label_dictionary[0]],\n",
    "    crop_extent=15.0,\n",
    "    crop_extent_option=dgstreams.CropExtentOptions.ASPECT_RATIO_ADJUSTMENT_BY_LONG_SIDE,\n",
    ")  # cropping gizmo, which accepts only objects in counting zone\n",
    "age = dgstreams.AiSimpleGizmo(age_det_model)  # age regression\n",
    "gender = dgstreams.AiSimpleGizmo(gender_det_model)  # gender classifier\n",
    "combiner = dgstreams.CropCombiningGizmo(2)  # combiner with 2 inputs\n",
    "display = dgstreams.VideoDisplayGizmo(\n",
    "    [\"Stream\"], show_ai_overlay=True, show_fps=True\n",
    ")  # display\n",
    "sink = dgstreams.SinkGizmo()  # result sink\n",
    "\n",
    "#\n",
    "# run composition\n",
    "#\n",
    "stats = {}\n",
    "with dgstreams.Composition(\n",
    "    source >> person >> analyzer >> crop,\n",
    "    analyzer >> combiner[0] >> sink,\n",
    "    crop >> age >> combiner[1],\n",
    "    crop >> gender >> combiner[2],\n",
    "    analyzer >> display,\n",
    "):\n",
    "    for data in sink():\n",
    "        result = data.meta.find_last(dgstreams.tag_inference)\n",
    "        frame_info = data.meta.find_last(dgstreams.tag_video)\n",
    "        for obj in result.results:\n",
    "            track_id = obj.get(\"track_id\")\n",
    "            extra_results = obj.get(dgstreams.CropCombiningGizmo.key_extra_results)\n",
    "            if track_id is not None and extra_results:\n",
    "                stat = stats.setdefault(track_id, {\"scores\": {}})\n",
    "                for res in extra_results:\n",
    "                    score_pair = stat[\"scores\"].setdefault(\n",
    "                        res.results[0][\"label\"], [0, 0]\n",
    "                    )\n",
    "                    score_pair[0] += res.results[0][\"score\"]\n",
    "                    score_pair[1] += 1\n",
    "                    stat[\"image\"] = res.image\n",
    "                    stat[\"frame_info\"] = frame_info\n",
    "\n",
    "#\n",
    "# print statistics\n",
    "#\n",
    "for track_id, stat in stats.items():\n",
    "    degirum_tools.ipython_display(stat[\"image\"])\n",
    "    print(\n",
    "        f\"ID: {track_id} ({time.ctime(stat['frame_info'][dgstreams.VideoSourceGizmo.key_timestamp])})\"\n",
    "    )\n",
    "    for label, score_pair in stat[\"scores\"].items():\n",
    "        print(\n",
    "            f\"  {label}: {score_pair[0]/score_pair[1]:.2f} ({score_pair[1]} occurrences)\"\n",
    "        )\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c826275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
