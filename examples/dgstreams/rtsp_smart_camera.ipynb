{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "438aa03a",
   "metadata": {},
   "source": [
    "![Degirum banner](https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/images/degirum_banner.png)\n",
    "## This notebook is an example of how to stream AI annotated video with RTSP protocol. \n",
    "A video stream from local camera is processed by the person detection model. The media server is launched. The annotated video stream is then streamed out as RTSP stream to the media server.\n",
    "The media server can serve both RTSP and and WebRTC streams to multiple clients.\n",
    "Once this script is running, you can access the WebRTC stream at the following URL: http://localhost:8888/my-ai-stream/\n",
    "You can access the RTSP stream at the following URL: rtsp://localhost:8554/my-ai-stream/\n",
    "\n",
    "This example uses `degirum_tools.streams` streaming toolkit.\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. Run inference on DeGirum Cloud Platform;\n",
    "2. Run inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN;\n",
    "3. Run inference on DeGirum ORCA accelerator directly installed on your computer.\n",
    "\n",
    "To try different options, you need to specify the appropriate `hw_location` option. \n",
    "\n",
    "When running this notebook locally, you need to specify your cloud API access token in the [env.ini](../../env.ini) file, located in the same directory as this notebook.\n",
    "\n",
    "The script can use either local camera or web camera connected to the machine, or a video file. The camera index or URL or video file path needs to be specified in the code below by assigning `video_source`.\n",
    "\n",
    "You need to install MediaMTX and FFmpeg programs on your system, so they are available in the system PATH.\n",
    "Please refer to https://github.com/bluenviron/mediamtx for MediaMTX installation instructions.\n",
    "Please refer to https://ffmpeg.org/download.html for FFmpeg installation instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e17ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure degirum-tools package is installed\n",
    "!pip show degirum-tools || pip install degirum-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac1ad6f-2290-44fe-bcfd-4715f594ce57",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Specify where do you want to run your inferences, model_zoo_url, model names for inference, and video source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d33374c-e516-4b5f-b306-d18bf6392c52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hw_location: where you want to run inference\n",
    "#     \"@cloud\" to use DeGirum cloud\n",
    "#     \"@local\" to run on local machine\n",
    "#     IP address for AI server inference\n",
    "# model_zoo_url: url/path for model zoo\n",
    "#     cloud_zoo_url: valid for @cloud, @local, and ai server inference options\n",
    "#     '': ai server serving models from local folder\n",
    "#     path to json file: single model zoo in case of @local inference\n",
    "# people_det_model_name: name of the model for detecting people\n",
    "# pose_det_model_name: name of the model for pose detection\n",
    "# video_source: video source for inference\n",
    "#     camera index for local camera\n",
    "#     URL of RTSP stream\n",
    "#     URL of YouTube Video\n",
    "#     path to video file (mp4 etc)\n",
    "# url_path: path for the RTSP server to serve the video stream\n",
    "hw_location = \"@cloud\"\n",
    "model_zoo_url = \"degirum/public\"\n",
    "model_name = \"yolo_v5s_person_det--512x512_quant_n2x_orca1_1\"\n",
    "video_source = 0 # local camera\n",
    "url_path = \"/my-ai-stream\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e036ab35-cc8f-4e67-bf5b-f01c470db2a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d4cd90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import degirum as dg, degirum_tools, time\n",
    "from degirum_tools import streams as dgstreams\n",
    "\n",
    "# load model\n",
    "model = dg.load_model(\n",
    "    model_name,\n",
    "    hw_location,\n",
    "    model_zoo_url,\n",
    "    degirum_tools.get_token(),\n",
    "    overlay_show_probabilities=True,\n",
    "    overlay_line_width=1,\n",
    ")\n",
    "\n",
    "# create gizmos\n",
    "\n",
    "# video source gizmo\n",
    "cam_source = dgstreams.VideoSourceGizmo(video_source)\n",
    "\n",
    "# detection gizmo\n",
    "detector = dgstreams.AiSimpleGizmo(model)\n",
    "\n",
    "# video streamer gizmo\n",
    "streamer = dgstreams.VideoStreamerGizmo(f\"rtsp://localhost:8554{url_path}\", show_ai_overlay=True)\n",
    "\n",
    "# local display gizmo (just for debugging)\n",
    "display = dgstreams.VideoDisplayGizmo(show_ai_overlay=True)\n",
    "\n",
    "# start media server to serve RTSP streams\n",
    "with degirum_tools.MediaServer():\n",
    "    # connect gizmos into pipeline and start composition\n",
    "    dgstreams.Composition(cam_source >> detector >> streamer, detector >> display).start()\n",
    "\n",
    "#\n",
    "# You can access the WebRTC stream at the following URL: http://localhost:8888/my-ai-stream/\n",
    "# You can access the RTSP stream at the following URL: rtsp://localhost:8554/my-ai-stream/\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
