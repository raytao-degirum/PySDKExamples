{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06f07a3d",
   "metadata": {},
   "source": [
    "![Degirum banner](https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/images/degirum_banner.png)\n",
    "## Hand Tracking and Palm Keypoint Detection Sample\n",
    "\n",
    "This notebook is an example of how to perform hand detection with tracking with following detection of palm keypoints.\n",
    "The combined result of hand detection and palm keypoints detection is used to imitate mouse operation.\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. Run inference on DeGirum Cloud Platform;\n",
    "2. Run inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN;\n",
    "3. Run inference on DeGirum ORCA accelerator directly installed on your computer.\n",
    "\n",
    "To try different options, you need to specify the appropriate `hw_location` option.\n",
    "\n",
    "When running this notebook locally, you need to specify your cloud API access token in the [env.ini](../../env.ini) file, located in the same directory as this notebook.\n",
    "\n",
    "When running this notebook in Google Colab, the cloud API access token should be stored in a user secret named `DEGIRUM_CLOUD_TOKEN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6e60df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure degirum-tools package and other dependencies are installed\n",
    "!pip show degirum-tools || pip install degirum-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d275dc8",
   "metadata": {},
   "source": [
    "#### Specify where you want to run your inferences, model zoo url, model name and image source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec502de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hw_location: where you want to run inference\n",
    "#     @cloud to use DeGirum cloud\n",
    "#     @local to run on local machine\n",
    "#     IP address for AI server inference\n",
    "# model_zoo_url: url/path for model zoo\n",
    "#     cloud_zoo_url: valid for @cloud, @local, and ai server inference options\n",
    "#     '': ai server serving models from local folder\n",
    "#     path to json file: single model zoo in case of @local inference\n",
    "# video_source: video source for inference\n",
    "#     camera index for local camera\n",
    "#     URL of RTSP stream\n",
    "#     URL of YouTube Video\n",
    "#     path to video file (mp4 etc)\n",
    "hw_location = \"@cloud\"\n",
    "model_zoo_url = \"degirum/public\"\n",
    "video_source = \"https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/images/HandPalm.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140d41d1-85f6-442c-a3d3-4a7fafaebcef",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6121d72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import degirum as dg, degirum_tools\n",
    "import cv2, numpy as np\n",
    "\n",
    "# load hand bbox detection model\n",
    "hand_model = dg.load_model(\n",
    "    model_name= \"yolo_v5s_hand_det--512x512_quant_n2x_orca1_1\",\n",
    "    inference_host_address=hw_location,\n",
    "    zoo_url=model_zoo_url,\n",
    "    token=degirum_tools.get_token(),\n",
    "    overlay_show_probabilities=False,\n",
    "    overlay_show_labels=False,\n",
    "    overlay_line_width=1,\n",
    ")\n",
    "\n",
    "# load palm landmarks detection model\n",
    "palm_model = dg.load_model(\n",
    "    model_name= \"mobilenet_v2_hand_landmarks--224x224_float_n2x_orca1_1\",\n",
    "    inference_host_address=hw_location,\n",
    "    zoo_url=model_zoo_url,\n",
    "    token=degirum_tools.get_token(),\n",
    "    overlay_show_probabilities=False,\n",
    "    overlay_show_labels=False,\n",
    "    overlay_line_width=1,\n",
    ")\n",
    "\n",
    "# create object tracker\n",
    "tracker = degirum_tools.ObjectTracker(\n",
    "    track_thresh=0.35,\n",
    "    track_buffer=100,\n",
    "    match_thresh=0.9999,\n",
    "    anchor_point=degirum_tools.AnchorPoint.CENTER,\n",
    ")\n",
    "\n",
    "# create object selector to track only one hand\n",
    "selector = degirum_tools.ObjectSelector(\n",
    "    top_k=1,\n",
    "    use_tracking=True,\n",
    "    selection_strategy=degirum_tools.ObjectSelectionStrategies.LARGEST_AREA,\n",
    ")\n",
    "\n",
    "# attach object tracker and object selector analyzers to hand model\n",
    "degirum_tools.attach_analyzers(hand_model, [tracker, selector])\n",
    "\n",
    "# create compound model for hand detection and palm landmarks detection\n",
    "model = degirum_tools.CroppingAndDetectingCompoundModel(\n",
    "    hand_model,\n",
    "    palm_model,\n",
    "    crop_extent=30.0,\n",
    ")\n",
    "\n",
    "# define palm landmarks to be filtered\n",
    "palm_landmarks = [\n",
    "    \"ThumbTip\",\n",
    "    \"IndexFingerTip\",\n",
    "    \"IndexFingerMCP\",\n",
    "    \"MiddleFingerTip\",\n",
    "    \"MiddleFingerMCP\",\n",
    "    \"Wrist\",\n",
    "]\n",
    "\n",
    "# create low-pass filters for palm landmarks\n",
    "lpf = {\n",
    "    pt: degirum_tools.FIRFilterLP(normalized_cutoff=0.1, taps_cnt=7, dimension=3)\n",
    "    for pt in palm_landmarks\n",
    "}\n",
    "\n",
    "# inference loop\n",
    "with degirum_tools.Display(\"AI Camera\") as display:\n",
    "    for inference_result in degirum_tools.predict_stream(model, video_source):\n",
    "        image = inference_result.image_overlay\n",
    "        if inference_result.results:\n",
    "            for r in inference_result.results:\n",
    "\n",
    "                if \"landmarks\" in r:\n",
    "\n",
    "                    def landmark(results, label):\n",
    "                        try:\n",
    "                            return next(\n",
    "                                r for r in results if r.get(\"label\", \"\") == label\n",
    "                            ).get(\"landmark\", None)\n",
    "                        except StopIteration:\n",
    "                            return None\n",
    "\n",
    "                    # filter landmark coordinates\n",
    "                    coords = {\n",
    "                        pt: lpf[pt](landmark(r[\"landmarks\"], pt)).astype(int)\n",
    "                        for pt in palm_landmarks\n",
    "                    }\n",
    "\n",
    "                    # detect proximity of thumb tip to other finger tips\n",
    "                    d1 = np.linalg.norm(coords[\"ThumbTip\"] - coords[\"IndexFingerTip\"])\n",
    "                    d2 = np.linalg.norm(coords[\"ThumbTip\"] - coords[\"MiddleFingerTip\"])\n",
    "                    thr = 0.2 * (\n",
    "                        np.linalg.norm(coords[\"IndexFingerMCP\"] - coords[\"Wrist\"])\n",
    "                        + np.linalg.norm(coords[\"MiddleFingerMCP\"] - coords[\"Wrist\"])\n",
    "                    )\n",
    "                    clicked = (d1 + d2) * 0.5 < thr\n",
    "\n",
    "                    # draw position of index finger tip and click status\n",
    "                    pos = coords[\"IndexFingerTip\"][:2]\n",
    "                    cv2.circle(image, pos, 7, (0, 0, 255))\n",
    "                    if clicked:\n",
    "                        degirum_tools.put_text(\n",
    "                            image,\n",
    "                            \"CLICK!\",\n",
    "                            pos + 10,\n",
    "                            font_color=(0, 0, 255),\n",
    "                        )\n",
    "\n",
    "        display.show(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (supervision)",
   "language": "python",
   "name": "supervision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
