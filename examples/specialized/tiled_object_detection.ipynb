{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c15cb24",
   "metadata": {},
   "source": [
    "## Tiled object detection from a video file\n",
    "This notebook is an example of how to use DeGirum PySDK to do tiled object detection of a video stream from a video file.\n",
    "Each video frame is divided by tiles with some overlap, each tile of the AI model input size (to avoid resizing).\n",
    "Object detection is performed for each tile, then results from different tiles are combined.\n",
    "\n",
    "For comparison purpose, non-tiled object detection with the same model is performed on the same video.\n",
    "Results of tiled and non-tiled object detection are then combined on a single video.\n",
    "\n",
    "This script works with the following inference options:\n",
    "\n",
    "1. Run inference on DeGirum Cloud Platform;\n",
    "2. Run inference on DeGirum AI Server deployed on a localhost or on some computer in your LAN or VPN;\n",
    "3. Run inference on DeGirum ORCA accelerator directly installed on your computer.\n",
    "\n",
    "To try different options, you need to specify the appropriate `hw_location` option.\n",
    "\n",
    "When running this notebook locally, you need to specify your cloud API access token in the [env.ini](../../env.ini) file, located in the same directory as this notebook.\n",
    "\n",
    "When running this notebook in Google Colab, the cloud API access token should be stored in a user secret named `DEGIRUM_CLOUD_TOKEN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b018f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure degirum-tools package is installed\n",
    "!pip show degirum-tools || pip install degirum-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01549d7c-2445-4007-8a89-ac0f3a864530",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Specify video file name, model name, and other options here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da34df11-cbc7-4b00-8994-794a4a6548b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hw_location: where you want to run inference\n",
    "#     \"@cloud\" to use DeGirum cloud\n",
    "#     \"@local\" to run on local machine\n",
    "#     IP address for AI server inference\n",
    "# video_source: video source for inference\n",
    "#     camera index for local camera\n",
    "#     URL of RTSP stream\n",
    "#     URL of YouTube Video\n",
    "#     path to video file (mp4 etc)\n",
    "# model_name: name of the model for running AI inference\n",
    "# model_zoo_url: url/path for model zoo\n",
    "#     cloud_zoo_url: valid for @cloud, @local, and ai server inference options\n",
    "#     '': ai server serving models from local folder\n",
    "#     path to json file: single model zoo in case of @local inference\n",
    "# classes: list of classes to show\n",
    "# *_ann_path: paths to save annotated videos\n",
    "hw_location = \"@cloud\"\n",
    "video_source = \"https://raw.githubusercontent.com/DeGirum/PySDKExamples/main/images/Traffic.mp4\"\n",
    "model_name = \"yolo_v5s_coco--512x512_quant_n2x_orca1_1\"\n",
    "model_zoo_url = \"degirum/public\"\n",
    "classes = {\"car\"}\n",
    "tiled_ann_path = \"temp/tiled_object_detection.mp4\"\n",
    "non_tiled_ann_path = \"temp/non-tiled_object_detection.mp4\"\n",
    "combined_ann_path = \"temp/combined_object_detection.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1b821-e18e-403b-8147-9f95fc6cfa34",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The rest of the cells below should run without any modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e512335c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np, degirum as dg, degirum_tools\n",
    "\n",
    "# load object detection model\n",
    "model = dg.load_model(\n",
    "    model_name=model_name,\n",
    "    inference_host_address=hw_location,\n",
    "    zoo_url=model_zoo_url,\n",
    "    token=degirum_tools.get_token(),\n",
    "    output_class_set=classes,\n",
    "    overlay_show_labels=False,\n",
    "    overlay_show_probabilities=False,\n",
    "    overlay_line_width=1,\n",
    "    overlay_color=(0, 255, 0),\n",
    ")\n",
    "\n",
    "with degirum_tools.open_video_stream(video_source) as video_stream:\n",
    "    model_size = model.model_info.InputW + model.model_info.InputH\n",
    "    frame_size = degirum_tools.get_video_stream_properties(video_stream)[:2]\n",
    "\n",
    "    # calculate tiles for tiled inference\n",
    "    tiles = degirum_tools.generate_tiles_fixed_size(\n",
    "        model_size, frame_size, min_overlap_percent=5.0\n",
    "    )\n",
    "    tiles = tiles[0] # pick top row of tiles\n",
    "\n",
    "    # define tile extractor pseudo-model\n",
    "    tile_extractor = degirum_tools.RegionExtractionPseudoModel(tiles, model)\n",
    "\n",
    "    # define NMS options; for tiling, the best approach is to use IoS \n",
    "    # instead of IoU and use LARGEST_AREA box selection policy\n",
    "    nms_options = degirum_tools.NmsOptions(\n",
    "        threshold=0.3,\n",
    "        use_iou=False,\n",
    "        box_select=degirum_tools.NmsBoxSelectionPolicy.LARGEST_AREA,\n",
    "    )\n",
    "\n",
    "    # define compound model, which combines tile extractor and object detection model\n",
    "    compound_model = degirum_tools.CroppingAndDetectingCompoundModel(\n",
    "        tile_extractor, model, nms_options=nms_options\n",
    "    )\n",
    "\n",
    "    # run tiled inference on video stream\n",
    "    degirum_tools.annotate_video(compound_model, video_stream, tiled_ann_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2182e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run regular inference on video stream\n",
    "model.overlay_color=(255, 0, 0)\n",
    "degirum_tools.annotate_video(model, video_source, non_tiled_ann_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967696b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two annotated videos into single video for comparison\n",
    "import cv2\n",
    "\n",
    "with degirum_tools.open_video_stream(non_tiled_ann_path) as non_tiled_stream:\n",
    "    with degirum_tools.open_video_stream(tiled_ann_path) as tiled_stream:\n",
    "        with degirum_tools.open_video_writer(\n",
    "            combined_ann_path,\n",
    "            *degirum_tools.get_video_stream_properties(tiled_stream)[:2]\n",
    "        ) as writer:\n",
    "\n",
    "            progress = degirum_tools.Progress(tiled_stream.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            for tiled_frame, non_tiled_frame in zip(\n",
    "                degirum_tools.video_source(tiled_stream),\n",
    "                degirum_tools.video_source(non_tiled_stream),\n",
    "            ):\n",
    "                # insert top half of non_tiled_frame into bottom half of tiled_frame\n",
    "                half_height = tiled_frame.shape[0] // 2\n",
    "                tiled_frame[half_height:, :] = non_tiled_frame[:half_height, :]\n",
    "                writer.write(tiled_frame)\n",
    "                progress.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367f1796",
   "metadata": {},
   "outputs": [],
   "source": [
    "degirum_tools.ipython_display(combined_ann_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfda9ce",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
